<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png"><link rel="icon" href="/img/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Fulequn"><meta name="keywords" content=""><meta name="description" content="参考链接： https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;4c6c8174f292  R中的线性回归函数比较简单，就是lm()，比较复杂的是对线性模型的诊断和调整。这里结合Statistical Learning和杜克大学的Data Analysis and Statistical Inference的章节以及《R语言实战》的OLS(Ordinary Least Square)回归模型章节"><meta property="og:type" content="article"><meta property="og:title" content="R做多元线性回归全攻略"><meta property="og:url" content="https://fulequn.github.io/2020/10/Article202010084/index.html"><meta property="og:site_name" content="FuLeQun&#39;s Blog"><meta property="og:description" content="参考链接： https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;4c6c8174f292  R中的线性回归函数比较简单，就是lm()，比较复杂的是对线性模型的诊断和调整。这里结合Statistical Learning和杜克大学的Data Analysis and Statistical Inference的章节以及《R语言实战》的OLS(Ordinary Least Square)回归模型章节"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910818.jpg"><meta property="og:image" content="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910820.jpg"><meta property="og:image" content="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910821.jpg"><meta property="og:image" content="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910822.jpg"><meta property="og:image" content="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910823.jpg"><meta property="article:published_time" content="2020-10-08T15:42:08.000Z"><meta property="article:modified_time" content="2024-05-18T14:35:07.521Z"><meta property="article:author" content="Fulequn"><meta property="article:tag" content="R"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910818.jpg"><title>R做多元线性回归全攻略 - FuLeQun&#39;s Blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"fulequn.github.io",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1},gtag:null,tajs:null},search_path:"/local-search.xml",include_content_in_search:!0};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.2.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>FuLeQun&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="R做多元线性回归全攻略"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2020-10-08 23:42" pubdate>2020年10月8日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i>2.4k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i>20 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">R做多元线性回归全攻略</h1><div class="markdown-body"><blockquote><p>参考链接：</p><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4c6c8174f292">https://www.jianshu.com/p/4c6c8174f292</a></p></blockquote><p>R中的线性回归函数比较简单，就是lm()，比较复杂的是对线性模型的诊断和调整。这里结合Statistical Learning和杜克大学的Data Analysis and Statistical Inference的章节以及《R语言实战》的OLS(Ordinary Least Square)回归模型章节来总结一下，诊断多元线性回归模型的操作分析步骤。</p><p><strong>1、选择预测变量</strong></p><p>因变量比较容易确定，多元回归模型中难在自变量的选择。自变量选择主要可分为向前选择（逐次加使RSS最小的自变量），向后选择（逐次扔掉p值最大的变量）。个人倾向于向后选择法，一来p值比较直观，模型返回结果直接给出了各变量的p值，却没有直接给出RSS；二来当自变量比较多时，一个个加比较麻烦。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs R">Call<span class="hljs-operator">:</span><br>lm<span class="hljs-punctuation">(</span>formula <span class="hljs-operator">=</span> Sales <span class="hljs-operator">~</span> . <span class="hljs-operator">+</span> Income<span class="hljs-operator">:</span>Advertising <span class="hljs-operator">+</span> Age<span class="hljs-operator">:</span>Price<span class="hljs-punctuation">,</span> data <span class="hljs-operator">=</span> Carseats<span class="hljs-punctuation">)</span><br>Residuals<span class="hljs-operator">:</span><br>Min      <span class="hljs-number">1</span>Q  Median      <span class="hljs-number">3</span>Q     Max<br><span class="hljs-operator">-</span><span class="hljs-number">2.9208</span> <span class="hljs-operator">-</span><span class="hljs-number">0.7503</span>  <span class="hljs-number">0.0177</span>  <span class="hljs-number">0.6754</span>  <span class="hljs-number">3.3413</span><br>Coefficients<span class="hljs-operator">:</span><br>Estimate Std. Error t value Pr<span class="hljs-punctuation">(</span><span class="hljs-operator">&gt;</span><span class="hljs-operator">|</span>t<span class="hljs-operator">|</span><span class="hljs-punctuation">)</span><br><span class="hljs-punctuation">(</span>Intercept<span class="hljs-punctuation">)</span>         <span class="hljs-number">6.5755654</span>  <span class="hljs-number">1.0087470</span>   <span class="hljs-number">6.519</span> <span class="hljs-number">2.22e-10</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>CompPrice           <span class="hljs-number">0.0929371</span>  <span class="hljs-number">0.0041183</span>  <span class="hljs-number">22.567</span>  <span class="hljs-operator">&lt;</span> <span class="hljs-number">2e-16</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>Income              <span class="hljs-number">0.0108940</span>  <span class="hljs-number">0.0026044</span>   <span class="hljs-number">4.183</span> <span class="hljs-number">3.57e-05</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>Advertising         <span class="hljs-number">0.0702462</span>  <span class="hljs-number">0.0226091</span>   <span class="hljs-number">3.107</span> <span class="hljs-number">0.002030</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>Population          <span class="hljs-number">0.0001592</span>  <span class="hljs-number">0.0003679</span>   <span class="hljs-number">0.433</span> <span class="hljs-number">0.665330</span><br>Price              <span class="hljs-operator">-</span><span class="hljs-number">0.1008064</span>  <span class="hljs-number">0.0074399</span> <span class="hljs-operator">-</span><span class="hljs-number">13.549</span>  <span class="hljs-operator">&lt;</span> <span class="hljs-number">2e-16</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>ShelveLocGood       <span class="hljs-number">4.8486762</span>  <span class="hljs-number">0.1528378</span>  <span class="hljs-number">31.724</span>  <span class="hljs-operator">&lt;</span> <span class="hljs-number">2e-16</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>ShelveLocMedium     <span class="hljs-number">1.9532620</span>  <span class="hljs-number">0.1257682</span>  <span class="hljs-number">15.531</span>  <span class="hljs-operator">&lt;</span> <span class="hljs-number">2e-16</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>Age                <span class="hljs-operator">-</span><span class="hljs-number">0.0579466</span>  <span class="hljs-number">0.0159506</span>  <span class="hljs-operator">-</span><span class="hljs-number">3.633</span> <span class="hljs-number">0.000318</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>Education          <span class="hljs-operator">-</span><span class="hljs-number">0.0208525</span>  <span class="hljs-number">0.0196131</span>  <span class="hljs-operator">-</span><span class="hljs-number">1.063</span> <span class="hljs-number">0.288361</span><br>UrbanYes            <span class="hljs-number">0.1401597</span>  <span class="hljs-number">0.1124019</span>   <span class="hljs-number">1.247</span> <span class="hljs-number">0.213171</span><br>USYes              <span class="hljs-operator">-</span><span class="hljs-number">0.1575571</span>  <span class="hljs-number">0.1489234</span>  <span class="hljs-operator">-</span><span class="hljs-number">1.058</span> <span class="hljs-number">0.290729</span><br>Income<span class="hljs-operator">:</span>Advertising  <span class="hljs-number">0.0007510</span>  <span class="hljs-number">0.0002784</span>   <span class="hljs-number">2.698</span> <span class="hljs-number">0.007290</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><br>Price<span class="hljs-operator">:</span>Age           <span class="hljs-number">0.0001068</span>  <span class="hljs-number">0.0001333</span>   <span class="hljs-number">0.801</span> <span class="hljs-number">0.423812</span><br><span class="hljs-operator">-</span><span class="hljs-operator">-</span><span class="hljs-operator">-</span><br>Signif. codes<span class="hljs-operator">:</span>  <span class="hljs-number">0</span> ‘<span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span>’ <span class="hljs-number">0.001</span> ‘<span class="hljs-operator">*</span><span class="hljs-operator">*</span>’ <span class="hljs-number">0.01</span> ‘<span class="hljs-operator">*</span>’ <span class="hljs-number">0.05</span> ‘.’ <span class="hljs-number">0.1</span> ‘ ’ <span class="hljs-number">1</span><br>Residual standard error<span class="hljs-operator">:</span> <span class="hljs-number">1.011</span> on <span class="hljs-number">386</span> degrees of freedom<br>Multiple R<span class="hljs-operator">-</span>squared<span class="hljs-operator">:</span>  <span class="hljs-number">0.8761</span><span class="hljs-punctuation">,</span>    Adjusted R<span class="hljs-operator">-</span>squared<span class="hljs-operator">:</span>  <span class="hljs-number">0.8719</span><br><span class="hljs-built_in">F</span><span class="hljs-operator">-</span>statistic<span class="hljs-operator">:</span>   <span class="hljs-number">210</span> on <span class="hljs-number">13</span> and <span class="hljs-number">386</span> DF<span class="hljs-punctuation">,</span>  p<span class="hljs-operator">-</span>value<span class="hljs-operator">:</span> <span class="hljs-operator">&lt;</span> <span class="hljs-number">2.2e-16</span><br></code></pre></td></tr></table></figure><p>构建一个回归模型后，先看F统计量的p值，这是对整个模型的假设检验，原假设是各系数都为0，如果连这个p值都不显著，无法证明至少有一个自变量对因变量有显著性影响，这个模型便不成立。然后看Adjusted R2，每调整一次模型，应该使它变大；Adjusted R2越大说明模型中相关的自变量对因变量可解释的变异比例越大，模型的预测性就越好。</p><p>构建了线性模型后，如果是一元线性回归，可以画模型图初步判断一下线性关系（多元回归模型不好可视化）：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs R">par<span class="hljs-punctuation">(</span>mfrow<span class="hljs-operator">=</span><span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>plot<span class="hljs-punctuation">(</span>medv<span class="hljs-operator">~</span>lstat<span class="hljs-punctuation">,</span>Boston<span class="hljs-punctuation">)</span><br>fit1<span class="hljs-operator">=</span>lm<span class="hljs-punctuation">(</span>medv<span class="hljs-operator">~</span>lstat<span class="hljs-punctuation">,</span>data<span class="hljs-operator">=</span>Boston<span class="hljs-punctuation">)</span><br>abline<span class="hljs-punctuation">(</span>fit1<span class="hljs-punctuation">,</span>col<span class="hljs-operator">=</span><span class="hljs-string">&quot;red&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910818.jpg" srcset="/img/loading.gif" lazyload alt="1"></p><p><strong>2、模型诊断</strong></p><p>确定了回归模型的自变量并初步得到一个线性回归模型，并不是直接可以拿来用的，还要进行验证和诊断。诊断之前，先回顾多元线性回归模型的假设前提（by Data Analysis and Statistical Inference）：</p><p>（数值型）自变量要与因变量有线性关系；</p><p>残差基本呈正态分布；</p><p>残差方差基本不变（同方差性）；</p><p>残差（样本）间相关独立。</p><p>一个好的多元线性回归模型应当尽量满足这4点假设前提。</p><p>用lm()构造一个线性模型fit后，plot(fit)即可返回4张图（可以par(mfrow=c(2,2))一次展现），这4张图可作初步检验：</p><p><img src="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910820.jpg" srcset="/img/loading.gif" lazyload alt="2"></p><p>左上图用来检验假设1，如果散点看不出什么规律，则表示线性关系良好，若有明显关系，则说明非线性关系明显。右上图用来检验假设2，若散点大致都集中在QQ图中的直线上，则说明残差正态性良好。左下图用来检验假设3，若点在曲线周围随机分布，则可认为假设3成立；若散点呈明显规律，比如方差随均值而增大，则越往右的散点上下间距会越大，方差差异就越明显。假设4的独立性无法通过这几张图来检验，只能通过数据本身的来源的意义去判断。</p><p>右下图是用来检验异常值。异常值与三个概念有关：</p><p>离群点：y远离散点主体区域的点</p><p>杠杆点：x远离散点主体区域的点，一般不影响回归直线的斜率</p><p>强影响点：影响回归直线的斜率，一般是高杠杆点。</p><p>对于多元线性回归，高杠杆点不一定就是极端点，有可能是各个变量的取值都正常，但仍然偏离散点主体。</p><p>对于异常值，可以谨慎地删除，看新的模型是否效果更好。</p><p>《R语言实战》里推荐了更好的诊断方法，总结如下。</p><p><strong>1、多元线性回归假设验证：</strong></p><p>gvlma包的gvlma()函数可对拟合模型的假设作综合验证，并对峰度、偏度进行验证。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs R">states <span class="hljs-operator">&lt;-</span> as.data.frame<span class="hljs-punctuation">(</span>state.x77<span class="hljs-punctuation">[</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Murder&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Population&quot;</span><span class="hljs-punctuation">,</span><br><span class="hljs-string">&quot;Illiteracy&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Income&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Frost&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><br>fit <span class="hljs-operator">&lt;-</span> lm<span class="hljs-punctuation">(</span>Murder <span class="hljs-operator">~</span> Population <span class="hljs-operator">+</span> Illiteracy <span class="hljs-operator">+</span> Income <span class="hljs-operator">+</span><br>Frost<span class="hljs-punctuation">,</span> data <span class="hljs-operator">=</span> states<span class="hljs-punctuation">)</span><br>library<span class="hljs-punctuation">(</span>gvlma<span class="hljs-punctuation">)</span><br>gvmodel <span class="hljs-operator">&lt;-</span> gvlma<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><br>summary<span class="hljs-punctuation">(</span>gvmodel<span class="hljs-punctuation">)</span><br>Call<span class="hljs-operator">:</span><br>gvlma<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> fit<span class="hljs-punctuation">)</span><br>Value p<span class="hljs-operator">-</span>value                Decision<br>Global Stat        <span class="hljs-number">2.7728</span>  <span class="hljs-number">0.5965</span> Assumptions acceptable.<br>Skewness           <span class="hljs-number">1.5374</span>  <span class="hljs-number">0.2150</span> Assumptions acceptable.<br>Kurtosis           <span class="hljs-number">0.6376</span>  <span class="hljs-number">0.4246</span> Assumptions acceptable.<br>Link Function      <span class="hljs-number">0.1154</span>  <span class="hljs-number">0.7341</span> Assumptions acceptable.<br>Heteroscedasticity <span class="hljs-number">0.4824</span>  <span class="hljs-number">0.4873</span> Assumptions acceptable.<br></code></pre></td></tr></table></figure><p>最后的Global Stat是对4个假设条件进行综合验证，通过了即表示4个假设验证都通过了。最后的Heterosceasticity是进行异方差检测。注意这里假设检验的原假设都是假设成立，所以当p&gt;0.05时，假设才能能过验证。</p><p>如果综合验证不通过，也有其他方法对4个假设条件分别验证：</p><p><strong>线性假设</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs R">library<span class="hljs-punctuation">(</span>car<span class="hljs-punctuation">)</span><br>crPlots<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910821.jpg" srcset="/img/loading.gif" lazyload alt="3"></p><p>返回的图是各个自变量与残差（因变量）的线性关系图，若存着明显的非线性关系，则需要对自变量作非线性转化。书中说这张图表明线性关系良好。</p><p><strong>正态性</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs R">library<span class="hljs-punctuation">(</span>car<span class="hljs-punctuation">)</span><br>qqPlot<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">,</span>labels <span class="hljs-operator">=</span> row.names<span class="hljs-punctuation">(</span>states<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>id.method <span class="hljs-operator">=</span> <span class="hljs-string">&quot;identify&quot;</span><span class="hljs-punctuation">,</span>simulate <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span>main <span class="hljs-operator">=</span> <span class="hljs-string">&quot;Q-Q Plot&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910822.jpg" srcset="/img/loading.gif" lazyload alt="4"></p><p>qqPlot()可以生成交互式的qq图，选中异常点，就返回该点的名称。该图中除了Nevad点，其他点都在直线附近，可见正态性良好。</p><p><strong>同方差性</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs R">library<span class="hljs-punctuation">(</span>car<span class="hljs-punctuation">)</span><br>ncvTest<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><br>Non<span class="hljs-operator">-</span>constant Variance Score Test<br>Variance formula<span class="hljs-operator">:</span> <span class="hljs-operator">~</span> fitted.values<br>Chisquare <span class="hljs-operator">=</span> <span class="hljs-number">1.746514</span>    Df <span class="hljs-operator">=</span> <span class="hljs-number">1</span>     p <span class="hljs-operator">=</span> <span class="hljs-number">0.1863156</span><br></code></pre></td></tr></table></figure><p>p值大于0.05，可认为满足方差相同的假设。</p><p><strong>独立性</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs R">library<span class="hljs-punctuation">(</span>car<span class="hljs-punctuation">)</span><br>durbinWatsonTest<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><br>lag Autocorrelation D<span class="hljs-operator">-</span>W Statistic p<span class="hljs-operator">-</span>value<br><span class="hljs-number">1</span>      <span class="hljs-operator">-</span><span class="hljs-number">0.2006929</span>      <span class="hljs-number">2.317691</span>   <span class="hljs-number">0.258</span><br>Alternative hypothesis<span class="hljs-operator">:</span> rho <span class="hljs-operator">!=</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>p值大于0.05，可认为误差之间相互独立。</p><p>除了以上4点基本假设，还有其他方面需要进行诊断——</p><p><strong>2、多重共线性</strong></p><p>理想中的线性模型各个自变量应该是线性无关的，若自变量间存在共线性，则会降低回归系数的准确性。一般用方差膨胀因子VIF(Variance Inflation Factor)来衡量共线性，《统计学习》中认为VIF超过5或10就存在共线性，《R语言实战》中认为VIF大于4则存在共线性。理想中的线性模型VIF=1，表完全不存在共线性。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs r">library<span class="hljs-punctuation">(</span>car<span class="hljs-punctuation">)</span><br>vif<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><br>Population Illiteracy     Income      Frost<br><span class="hljs-number">1.245282</span>   <span class="hljs-number">2.165848</span>   <span class="hljs-number">1.345822</span>   <span class="hljs-number">2.082547</span><br></code></pre></td></tr></table></figure><p>可见这4个自变量VIF都比较小，可认为不存在多重共线性的问题。</p><p><strong>3、异常值检验</strong></p><p>离群点</p><p>离群点有三种判断方法：一是用qqPlot()画QQ图，落在置信区间（上图中两条虚线）外的即可认为是离群点，如上图中的Nevad点；一种是判断学生标准化残差值，绝对值大于2（《R语言实战》中认为2，《统计学习》中认为3）的可认为是离群点。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs r">plot<span class="hljs-punctuation">(</span>x<span class="hljs-operator">=</span>fitted<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>y<span class="hljs-operator">=</span>rstudent<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>abline<span class="hljs-punctuation">(</span>h<span class="hljs-operator">=</span><span class="hljs-number">3</span><span class="hljs-punctuation">,</span>col<span class="hljs-operator">=</span><span class="hljs-string">&quot;red&quot;</span><span class="hljs-punctuation">,</span>lty<span class="hljs-operator">=</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span><br>abline<span class="hljs-punctuation">(</span>h<span class="hljs-operator">=</span><span class="hljs-operator">-</span><span class="hljs-number">3</span><span class="hljs-punctuation">,</span>col<span class="hljs-operator">=</span><span class="hljs-string">&quot;red&quot;</span><span class="hljs-punctuation">,</span>lty<span class="hljs-operator">=</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span><br>which<span class="hljs-punctuation">(</span><span class="hljs-built_in">abs</span><span class="hljs-punctuation">(</span>rstudent<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-operator">&gt;</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span><br>Nevada<br><span class="hljs-number">28</span><br></code></pre></td></tr></table></figure><p>还有一种方法是利用car包里的outlierTest()函数进行假设检验：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs r">library<span class="hljs-punctuation">(</span>car<span class="hljs-punctuation">)</span><br>outlierTest<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><br>rstudent unadjusted p<span class="hljs-operator">-</span>value Bonferonni p<br>Nevada <span class="hljs-number">3.542929</span>         <span class="hljs-number">0.00095088</span>     <span class="hljs-number">0.047544</span><br></code></pre></td></tr></table></figure><p>这个函数用来检验最大的标准化残差值，如果p&gt;0.05，可以认为没有离群点；若p&lt;0.05，则该点是离群点，但不能说明只有一个离群点，可以把这个点删除之后再作检验。第三种方法可以与第二种方法结合起来使用。</p><p><strong>高杠杆点</strong></p><p>高杠杆值观测点，即是与其他预测变量有关的离群点。换句话说，它们是由许多异常的预测变量值组合起来的，与响应变量值没有关系。《统计学习》中给出了一个杠杆统计量，《R语言实战》中给出了一种具体的操作方法。（两本书也稍有出入，《统计学习》中平均杠杆值为(p+1)/n，而在《R语言实战》中平均杠杆值为p/n；事实上在样本量n比较大时，几乎没有差别。）</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs r">hat.plot <span class="hljs-operator">&lt;-</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>p <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>coefficients<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>n <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>fitted<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>plot<span class="hljs-punctuation">(</span>hatvalues<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>main <span class="hljs-operator">=</span> <span class="hljs-string">&quot;Index Plot of Hat Values&quot;</span><span class="hljs-punctuation">)</span><br>abline<span class="hljs-punctuation">(</span>h<span class="hljs-operator">=</span><span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span><span class="hljs-operator">*</span>p<span class="hljs-operator">/</span>n<span class="hljs-punctuation">,</span>col<span class="hljs-operator">=</span><span class="hljs-string">&quot;red&quot;</span><span class="hljs-punctuation">,</span>lty<span class="hljs-operator">=</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span><br>identify<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>n<span class="hljs-punctuation">,</span> hatvalues<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">names</span><span class="hljs-punctuation">(</span>hatvalues<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span>  <span class="hljs-comment">#这句产生交互效果，选中某个点后，关闭后返回点的名称</span><br><span class="hljs-punctuation">&#125;</span><br>hat.plot<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/fulequn/oss_img/master/img231/202306241910823.jpg" srcset="/img/loading.gif" lazyload alt="5"></p><p>超过2倍或3倍的平均杠杆值即可认为是高杠杆点，这里把Alaska和California作为高杠杆点。</p><p><strong>强影响点</strong></p><p>强影响点是那种若删除则模型的系数会产生明显的变化的点。一种方法是计算Cook距离，一般来说， Cook’s D值大于4/(n-k -1)，则表明它是强影响点，其中n 为样本量大小， k 是预测变量数目。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs r">cutoff <span class="hljs-operator">&lt;-</span> 4<span class="hljs-operator">/</span><span class="hljs-punctuation">(</span>nrow<span class="hljs-punctuation">(</span>states<span class="hljs-operator">-</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>fit<span class="hljs-operator">$</span>coefficients<span class="hljs-punctuation">)</span><span class="hljs-operator">-</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-comment">#coefficients加上了截距项，因此要多减1</span><br>plot<span class="hljs-punctuation">(</span>fit<span class="hljs-punctuation">,</span>which<span class="hljs-operator">=</span><span class="hljs-number">4</span><span class="hljs-punctuation">,</span>cook.levels <span class="hljs-operator">=</span> cutoff<span class="hljs-punctuation">)</span><br>abline<span class="hljs-punctuation">(</span>h<span class="hljs-operator">=</span>cutoff<span class="hljs-punctuation">,</span>lty<span class="hljs-operator">=</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span>col<span class="hljs-operator">=</span><span class="hljs-string">&quot;red&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p>作者：真依然很拉风<br>链接：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4c6c8174f292">https://www.jianshu.com/p/4c6c8174f292</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" class="category-chain-item">编程语言</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/R/" class="print-no-link">#R</a></div></div><div class="license-box my-3"><div class="license-title"><div>R做多元线性回归全攻略</div><div>https://fulequn.github.io/2020/10/Article202010084/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Fulequn</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2020年10月8日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2020/10/Article202010131/" title="R语言解读多元线性回归模型"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">R语言解读多元线性回归模型</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2020/10/Article202010083/" title="【数据挖掘】使用R语言进行聚类分析"><span class="hidden-mobile">【数据挖掘】使用R语言进行聚类分析</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>