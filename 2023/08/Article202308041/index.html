<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png"><link rel="icon" href="/img/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Fulequn"><meta name="keywords" content=""><meta name="description" content="应聘的是蚂蚁金服的机器学习实习岗位的面试经验：  问题：求如何随机获得网页中的 K 个词。  面试官希望应聘者能够提出一个有效的方法，从一个包含大量词汇的网页中随机获取 K 个词。这个问题考察的是应聘者对数据结构和算法的理解和应用能力。首先，我们需要从网页中提取出所有的词汇。这可以通过使用网页爬虫和HTML解析器（如BeautifulSoup）来实现。然后，我们可以将所有的词汇存储在一个列表中。接"><meta property="og:type" content="article"><meta property="og:title" content="金融领域机器学习实习生面试经验与题目"><meta property="og:url" content="https://fulequn.github.io/2023/08/Article202308041/index.html"><meta property="og:site_name" content="FuLeQun&#39;s Blog"><meta property="og:description" content="应聘的是蚂蚁金服的机器学习实习岗位的面试经验：  问题：求如何随机获得网页中的 K 个词。  面试官希望应聘者能够提出一个有效的方法，从一个包含大量词汇的网页中随机获取 K 个词。这个问题考察的是应聘者对数据结构和算法的理解和应用能力。首先，我们需要从网页中提取出所有的词汇。这可以通过使用网页爬虫和HTML解析器（如BeautifulSoup）来实现。然后，我们可以将所有的词汇存储在一个列表中。接"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-08-04T14:37:50.000Z"><meta property="article:modified_time" content="2024-05-18T14:35:07.906Z"><meta property="article:author" content="Fulequn"><meta property="article:tag" content="DeepLearning"><meta property="article:tag" content="金融"><meta name="twitter:card" content="summary_large_image"><title>金融领域机器学习实习生面试经验与题目 - FuLeQun&#39;s Blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"fulequn.github.io",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1},gtag:null,tajs:null},search_path:"/local-search.xml",include_content_in_search:!0};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.2.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>FuLeQun&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="金融领域机器学习实习生面试经验与题目"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-08-04 22:37" pubdate>2023年8月4日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i>10k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i>84 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">金融领域机器学习实习生面试经验与题目</h1><div class="markdown-body"><p>应聘的是蚂蚁金服的机器学习实习岗位的面试经验：</p><ol><li><strong>问题</strong>：求如何随机获得网页中的 K 个词。<ul><li>面试官希望应聘者能够提出一个有效的方法，从一个包含大量词汇的网页中随机获取 K 个词。这个问题考察的是应聘者对数据结构和算法的理解和应用能力。首先，我们需要从网页中提取出所有的词汇。这可以通过使用网页爬虫和HTML解析器（如BeautifulSoup）来实现。然后，我们可以将所有的词汇存储在一个列表中。接着，我们可以使用Python的random模块中的sample函数来从列表中随机选择K个词。这个函数会返回一个新的列表，包含了原列表中随机选择的K个元素，且不会改变原列表。</li></ul></li><li>**问题：**对于一个图片检索引擎，有爬虫从网上获取图片，计算一个 MD5 码存储图片，然后该系统可以通过 MD5 码获取到存储的图片。面试官问我这个系统应该如何设计。<ul><li>**描述：**面试官希望应聘者能够提出一个有效的设计方案，用于实现一个可以通过 MD5 码获取存储图片的图片检索引擎。这个问题考察的是应聘者对系统设计的理解和应用能力。</li><li>这个系统可以分为三个主要部分：爬虫模块、存储模块和检索模块。<ul><li>爬虫模块负责从网上获取图片。这可以通过使用像Scrapy这样的爬虫框架来实现。</li><li>存储模块负责存储获取到的图片和它们对应的MD5码。首先，我们需要计算每个图片的MD5码。这可以通过使用Python的hashlib模块来实现。然后，我们可以将图片和它们的MD5码存储在一个数据库中。我们可以使用一个关系数据库（如MySQL）或一个键值数据库（如Redis）来实现这个功能。在这个数据库中，MD5码作为键，图片的存储路径或者图片的二进制数据作为值。</li><li>检索模块负责通过MD5码来检索图片。当用户提供一个MD5码时，检索模块会在数据库中查找对应的图片，并将其返回给用户。这可以通过使用数据库的查询功能来实现。</li></ul></li></ul></li><li>**问题：**项目经验分享<ul><li>**重点内容：**项目经验</li><li>**描述：**面试官希望应聘者能够分享他们在项目中的经验，包括他们在项目中使用的技术和解决问题的方法。这个问题考察的是应聘者的实践经验和问题解决能力。</li></ul></li></ol><p><strong>1. 公司：某蛋科技，岗位：数据挖掘工程师，行业方向：互联网金融</strong></p><p>一面技术：(1) 介绍一下自己的逾期还款率项目主要讲这个项目在什么场景下（P2P 借贷平台）应用什么技术手段（数据处理，特征工程，逻辑回归LR、随机森林RF、GBDT 训练，做 集成学习Ensemble, 调参）解决什么问题（对客户是否会逾期还款的预测，最后 AUC 达到了一个点：一般说 70%-80%，太低没多大用，太高有点假或者有过拟合的可能性，有明显的好坏用户的分辨能力）(2) 主要做了什么工作这块肯定要挑自己擅长的说，因为接下来面试官会根据你说的擅长的部分进一步进行提问与了解，因为面试的是数据挖掘的岗位，所以我主要讲的是特征工程（数据处理，特征选择：Filter、Wrapper、Enbedded、特征衍生），捎带着说了一点模型训练的事情(3) 常用数据从哪里来，大数据处理的方法和技术用过哪些其实对于一个互金公司的数据来源无非是两个方面，一个是自己业务中积累下来的，还有就是从外界买来的，但是这个问题如果只回答是自己公司的，有些面试官又会觉得不可思议，因为自己公司的数据不可能是全面的，而互金行业对数据量要求又大，所以不要入了面试官的坑。大数据处理方法就回答 spark 和 map-reduce，着重还是说 map-reduce。(4) 有一个 1T 大小的每行只有一个词汇的文本，怎么统计词的个数这个问题其实就是考察大数据处理中 map-reduce 的原理了，原理很简单就是‘分——合’的思想，就是对 HDFS 上的资源进行分片，map 阶段将数据分成 key-value 对，然后在 reduce 阶段再对 key 对应的 value 进行计数。这样就统计出了词的个数。结果：技术面顺利通过，二面 CRO，问我对互金的看法和风险化解等等业务上的问题，由于是第一场面试，对互金方面不算太了解，所以直接折在了二面。</p><p>集成学习是指构建并结合多个学习器来完成学习任务. 而集成学习主要分为两大类: 1, 个体学习器之间存在强依赖关系, 必须串行生成的序列化方法, 代表为“boosting”. 2, 个体学习器之间不存在依赖关系，可同时生成的并行化方法，代表是“bagging”和“随机森林(RF)”。在监督学习中衡量一个学习器的好坏可以通过比较Expected squared prediction error(EPE)。其中boosting方法主要减小偏差(Bias)而bagging的方法主要是减小方差(Variance)。</p><p>Logistic Regression 虽然被称为回归，但其实际上是分类模型，并常用于二分类。Logistic Regression 因其简单、可并行化、可解释强深受工业界喜爱。Logistic 回归的本质是：假设数据服从这个分布，然后使用极大似然估计做参数的估计</p><p>GBDT（Gradient Boosting Decision Tree）是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。GBDT的主要思想是，每一次构建模型是在之前已经构建的模型损失函数的梯度下降方向上进行构建。也就是说，每增加一个新的模型，都是为了使得之前模型的残差往梯度下降的方向减少，从而不断提升模型的预测准确性。</p><ol><li><strong>数据处理：</strong> 数据处理是特征工程的第一步，主要包括数据清洗、数据转换和数据规范化等步骤。<ul><li>数据清洗：去除重复值、处理缺失值和异常值等。</li><li>数据转换：将非数值型数据转换为数值型数据，如独热编码、标签编码等。</li><li>数据规范化：将数据转换到同一尺度，如最大最小规范化、Z-score规范化等。</li></ul></li><li><strong>特征选择：</strong> 特征选择是从原始特征中选择出对模型训练有用的特征，主要方法有Filter、Wrapper和Embedded三种。<ul><li>Filter：基于统计学方法，如卡方检验、互信息、相关系数等，评估单个特征和目标变量之间的关系，选择出有用的特征。</li><li>Wrapper：基于目标函数（如预测性能评价指标），通过递归特征消除、前向选择、后向删除等方法，选择出一组有用的特征。</li><li>Embedded：在模型训练过程中进行特征选择，如正则化方法（L1、L2）、树模型（决策树、随机森林、GBDT等）。</li></ul></li><li><strong>特征构造：</strong> 特征构造是基于原始特征，通过某种方式生成新的特征，以提取出更多的有效信息。主要方法有：<ul><li>特征交叉：将两个或多个特征进行组合，如特征A和特征B的交叉可以是A+B、A-B、A*B、A/B等。</li><li>特征衍生：基于业务知识，从原始特征中衍生出新的特征，如从日期特征衍生出“是否周末”、“是否节假日”等特征。</li><li>特征编码：将类别特征转换为数值特征，如独热编码、标签编码、目标编码等。</li></ul></li></ol><p><strong>2．公司：灵犀联云，岗位：算法工程师，行业方向：数据服务</strong></p><p>一面算法：(1) 编写二分查找算法思想就是从中间查找，比较大小后再找左或右半边，这个百度一下，各个语言版本都有，这个问题需要能够手写出来的，回去背吧(2) 二分查找的时间复杂度（O(logn)，最坏 O(n)），时间复杂度，空间复杂度怎么计算的其实这个就是看你代码执行的时间和占用空间，简单方法就是把常见的算法的时间复杂度和空间复杂度记下来，如果实在记不住就百度一下计算的过程(3) 简单问了一下工作经历和所作的工作（这跟第一个面试问的一样，然后就从头到尾的介绍一遍）(4) 在工作中用到了哪些算法，简单介绍这个肯定挑自己掌握度高的和简历中写的介绍，例如 LR，RF,SVM，然后说原理和推导过程。</p><p>二面技术：(1) 分类和聚类的区别从样本数据、模型、方法：分类 (LR，DT…)，聚类 (K-Means,K-Means++)，、产生的结果等方面阐述区别(2) 特征是怎么进行选择的或者说怎么知道选出来的就是最好的这个问题上面已经提过三种方法：Filter、Wrapper、Enbedded，主要从划分的属性上会像决策树生成过程中计算信息增益、增益率、Gini 一样评价一个属性的评分(3) L1 正则化和 L2 正则化的区别这个问题主要从公式，正则化形成过程，功能等方面进行回答，附一个我觉得讲的比较好的正则化的博客<a target="_blank" rel="noopener" href="https://blog.csdn.net/yuyang_1992/article/details/83685483">https://blog.csdn.net/yuyang_1992/article/details/83685483</a> (4)手推 SVM常用的机器学习算法大家最好还是可以手推出来的，因为有的面试官真的让你手推啊，手推之后回答了一下软间隔与硬间隔，核函数有哪些，区别，拉格朗日乘子法（西瓜书 SVM 那一章安排的明明白白）</p><p>三面人事：这个人事就很牛的样子，完全不是公平性谈判，打压你的信心，说什么他们那都是清华北大的毕业的，我不是名校出身，处于技术初级算法工程师阶段，希不希望有一个好的平台什么的，反正就是各种忽悠，然后压榨工资。这种情况也慢慢跟他聊，拿到 offer 是关键，只不过把它当备胎。结果：最后谈到了 16k / 月 * 14 个月，第二天发 offer。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment"># 返回 x 在 arr 中的索引，如果不存在返回 -1</span><br>def binarySearch (arr, l, r, x): <br>    <span class="hljs-comment"># 基本判断</span><br>    <span class="hljs-keyword">if</span> r &gt;= l: <br>        <span class="hljs-keyword">mid</span> = int(l + (r - l)/<span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 元素整好的中间位置</span><br>        <span class="hljs-keyword">if</span> arr[<span class="hljs-keyword">mid</span>] == x: <br>            <span class="hljs-literal">return</span> <span class="hljs-keyword">mid</span> <br>        <span class="hljs-comment"># 元素小于中间位置的元素，只需要再比较左边的元素</span><br>        elif arr[<span class="hljs-keyword">mid</span>] &gt; x: <br>            <span class="hljs-literal">return</span> binarySearch(arr, l, <span class="hljs-keyword">mid</span><span class="hljs-number">-1</span>, x) <br>        <span class="hljs-comment"># 元素大于中间位置的元素，只需要再比较右边的元素</span><br>        <span class="hljs-keyword">else</span>: <br>            <span class="hljs-literal">return</span> binarySearch(arr, <span class="hljs-keyword">mid</span>+<span class="hljs-number">1</span>, r, x) <br>    <span class="hljs-keyword">else</span>: <br>        <span class="hljs-comment"># 不存在</span><br>        <span class="hljs-literal">return</span> <span class="hljs-number">-1</span><br>  <br><span class="hljs-comment"># 测试数组</span><br>arr = [ <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">10</span>, <span class="hljs-number">40</span> ] <br>x = <span class="hljs-number">10</span><br><span class="hljs-comment"># 函数调用</span><br><span class="hljs-built_in">result</span> = binarySearch(arr, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(arr)<span class="hljs-number">-1</span>, x) <br><span class="hljs-keyword">if</span> <span class="hljs-built_in">result</span> != <span class="hljs-number">-1</span>: <br>    print (<span class="hljs-string">&quot;元素在数组中的索引为 %d&quot;</span> % <span class="hljs-built_in">result</span> )<br><span class="hljs-keyword">else</span>: <br>    print (<span class="hljs-string">&quot;元素不在数组中&quot;</span>)<br></code></pre></td></tr></table></figure><ol><li>分类和聚类的区别：<ul><li>分类是有监督学习，需要预先知道目标变量的分类标签。常用的分类算法有逻辑回归（LR），决策树（DT）等。分类的结果是预测出的特定类别。</li><li>聚类是无监督学习，不需要预先知道目标变量的分类标签。常用的聚类算法有K-Means，K-Means++等。聚类的结果是数据集中的自然分组。</li></ul></li><li>特征选择的方法：<ul><li>Filter：基于特征本身的指标（如信息增益、相关系数）进行筛选，不考虑模型效果。</li><li>Wrapper：基于模型的预测效果进行特征选择，如递归特征消除。</li><li>Embedded：在模型训练过程中进行特征选择，如L1/L2正则化。</li></ul></li><li>L1正则化和L2正则化的区别：<ul><li>L1正则化（Lasso）：在损失函数中加入参数的绝对值作为惩罚项，可以使得一些特征的系数变为0，从而达到特征选择的效果。</li><li>L2正则化（Ridge）：在损失函数中加入参数的平方作为惩罚项，可以使得特征的系数接近0，从而防止模型过拟合。</li></ul></li><li>SVM（支持向量机）：<ul><li>SVM是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；SVM还包括核技巧，这使它成为实质上的非线性分类器。</li><li>SVM的学习策略就是间隔最大化，可以形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。</li><li>SVM的学习算法是求解凸二次规划的最优化算法。</li></ul></li></ol><p><strong>3．公司：某贷网，岗位：算法工程师，行业方向：互联网金融</strong></p><p>一面技术：(1) 介绍自己的项目和主要工作 基本上是面试时的第一项，后面这一项就不写了(2)bagging 和 boosting 的区别，这个具体化其实就是 RF 和 GBDT 的区别：a. 样本选择方式；b. 样例权重；c. 预测函数；d. 并行计算(3) 语料库怎么构建词向量 这个问题就是偏自然语言处理方向的问题了，因为这是我在第一次写简历的一个败笔，写了一个自然语言处理的项目。但是也是硬着头皮说用到了 word2vect 进行构建词向量的…(4)TF-IDF 的计算方法，含义，应用场景 含义：词频 - 逆向文件频率，是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度 计算方式：TF 词在文件中出现频率；IDF：总文件数目除以包含该词语之文件的数目， 应用场景：其实就是自然语言处理中看一个词的重要性，然后对于文本分类这样的项目能够起到作用。(5)word2vect 的原理，两种模型形式，霍夫曼树？ word2vect 其实就是一个输入层，隐藏层和输出层这样的三层神经网络结构，一般分为 CBOW 和 Skip-Gram 两种形式，霍夫曼树是在训练 CBOW 和 Skip-Gram 优化的数据结构。上面这三个问题具体还包含很多小点，由于我不是主要面深度学习的，所以就不加以赘述了，大家可以上网查一下，附一个博客链接，一目了然：<a target="_blank" rel="noopener" href="https://blog.csdn.net/yuyang_1992/article/details/83685421">https://blog.csdn.net/yuyang_1992/article/details/83685421</a></p><p>二面直接上老大，问我有没有自然语言处理的实际落地项目，他们现在急招的是自然语言处理的岗位，算法工程师不急。听到这很忧伤，自然语言处理我没做重点复习啊，只能硬着说做过一个短文本分类小项目，然后做下介绍，闲扯了 10 分钟，感觉已经没戏了，所以有想面自然语言处理方向的同学一定要好好复习。</p><p><strong>4．公司：永辉云创，岗位：机器学习算法工程师，行业方向：机器学习</strong></p><p>一面技术： (1) 写一个快排，说一下快排主要快在哪？ 这个可以百度一下，原理，计算方法，代码应用尽有，主要快在它的思想是分而治之的思想，其实东西都是这个思想，例如分布式、hadoop 等 推荐一个关于快排的博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/pythondafahao/article/details/80084385">https://blog.csdn.net/pythondafahao/article/details/80084385</a> (2) 手推 SVM，什么是核函数，为什么要用核函数，SVM 核函数怎么选择？ 手推公式我这里就不写了，认准切入点是我们要找到一条直线正好把正负样本分割在两端，而且让它们离直线越远越好，之后进行了一系列的计算。 核函数是为了解决样本不是线性可分的问题提出来的，主要的核函数有线性核，高斯核，Sigmoid 核，核函数选择主要从训练集样本量，特征量上进行考虑。总之 SVM 的东西还是很多的，推导过程中还有拉格朗日乘子法、SMO 算法、软间隔、硬间隔等问题。 (3) SVM 和 LR 的异同点？ 这个我整理了一篇博客，直接上链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/yuyang_1992/article/details/83686204">https://blog.csdn.net/yuyang_1992/article/details/83686204</a> (4) 连续值特征做离散化有什么好处？ 同样这个问题博客见：<a target="_blank" rel="noopener" href="https://blog.csdn.net/yuyang_1992/article/details/83686284">https://blog.csdn.net/yuyang_1992/article/details/83686284</a> (5) 特征工程中对时序型特征怎么处理 时序特征其实是在预测上常用的一个特征，简单的来说我们可以根据特征中的时间特性来划分不同的时间区段 (比如，现在马上到双十一了，在时间特征上我们可以剥离出双 11，双 12，周末，工作日等)，这样会让特征有时序型 (其实就是特征工程中对时间类别特征的处理)，另外还有成熟的时序特诊处理方法 (这个需要自行去搜一下 paper),paper 较长，这里就不赘述了。 (6) 推荐系统的算法了解多少？简单介绍一下协同过滤，怎么计算商品之间的相似度？ 其实我了解的真不多，所以我就简单说知道协同过滤 (基于物品和基于用户)，其实就是一个人以类聚，物以群分的过程，然后说一下距离计算的方法：欧氏距离、Jaccard 相似度、Pearson 相似度、余弦相似度，最终形成一个打分的矩阵，然后根据得分进行推荐。 (7) 讲一下隐语义模型 思想是通过隐含特联系用户兴趣和物品，找出潜在的主题和分类，基于用户的行为对 item 进行自动聚类划分到不同类别 / 主题。知道这不是自己的强项，就跟面试官说只是了解，没有实际用过，但是我会回去好好研究研究，一副信誓旦旦的样子。 (8) 说说 hadoop 的原理，这又是大数据了，上面已经提到过了，大数据这块的东西大家还是好好看一下，因为现在搞算法，搞机器学习、深度学习都是在大数据的背景下的，所以这以后是一个基本的技能，面试官问的也比较多。 (9) 简历中的销售量预测的项目的评价指标召回率和 ACC 怎么协调 这个问题就看实际业务场景是更偏重于哪一方面了，我的回答 (不一定对) 是我们是先以准确率为准进行模型调优，达到我们可接受的数值时，然后往上调召回率，最终使两个指标都稳定。二面人事：人事没问什么特殊的问题，基本都是一个讨论，然后问一下工资，告知准备入职手续和材料。结果：永辉云创是永辉超市注资成立的，初创阶段，业务方向也是依托于用户超市数据搞大数据处理和探索人工智能其它方面。 顺利拿到 offer，20K / 月</p><ol><li>写一个快排，说一下快排主要快在哪？快速排序是一种基于“分而治之”思想的排序算法，能够通过递归地划分和排序来实现快速排序。其快速性主要来自于每次划分的平均时间复杂度是O(nlogn)。</li><li>手推 SVM，什么是核函数，为什么要用核函数，SVM 核函数怎么选择？<ul><li>重点内容：手动推导SVM，理解核函数的概念和作用，SVM核函数的选择方法。</li><li>描述：求职者需要手动推导SVM的过程，理解核函数是为了处理样本不是线性可分的情况，选择合适的核函数要考虑训练集样本量和特征量等因素。</li></ul></li><li>SVM 和 LR 的异同点？<ul><li>重点内容：SVM和LR的相似性和不同之处。</li><li>描述：求职者可以简单介绍SVM和LR的基本原理，然后着重强调它们在算法和模型上的异同点。</li></ul></li><li>连续值特征做离散化有什么好处？<ul><li>重点内容：连续值特征离散化的优势。</li><li>描述：离散化可以简化模型的复杂度，使得特征更容易被理解和解释，还可以帮助处理异常值和减少计算量。</li></ul></li><li>特征工程中对时序型特征怎么处理？<ul><li>重点内容：时序型特征在特征工程中的处理方法。</li><li>描述：求职者可以简单介绍根据时间特性划分时间区段的方法，并提及一些成熟的时序特征处理方法。</li></ul></li><li>讲一下隐语义模型。<ul><li>重点内容：隐语义模型的基本思想和应用。</li><li>描述：求职者可以简单介绍隐语义模型是如何通过潜在特征联系用户兴趣和物品，并实现自动聚类划分的。</li></ul></li><li>简历中的销售量预测的项目的评价指标召回率和 ACC 怎么协调？<ul><li>重点内容：召回率和准确率在销售量预测中的权衡。</li><li>描述：求职者可以结合具体业务场景，解释如何在召回率和准确率之间进行权衡，优化模型的调优。</li></ul></li></ol><p><strong>5．公司：百度金融，岗位：算法工程师，行业方向：互联网金融</strong></p><p>(1) 简单介绍自己，主要负责哪部分工作？ 这个就不说了，大家对这自己的简历都练几遍。尽量多说一点，这样面试官就少问一点。(2) 项目中用到的数据的量有多少？特征有多少维，都用作训练吗？ 这个问题是很多面试官都喜欢问的，要根据自己写的项目实际情况进行阐述，数据量较大的情况一般是不能全部用作训练的，要不然那模型得跑多长时间啊，还有就是特征维度，一般几十到几千维都有，用作训练的其实也就几十维到百维这样，特征工程那块肯定要看一下哪些特征是有用的，进行特征选择，如果全用会给训练带来大量的工作反而起到副作用。(3) 对大数据了解多少？hadoop 的原理？ 大数据处理其实上面已经提到过，用到的工具有 spark、hadoop，然后 hadoop 的原理就是分而治之，map-reduce 都干什么，建议写两个这样的程序你就能明白它是怎么工作的，这个很主要，因为工作中就是这么用的。(4) 特征怎么进行组合的，对模型训练有什么指导意义？ 特征组合一般都是拿差异性、关联性较大的特征进行组合，这样不会损失特征的作用，还可以拓展出未知的特征，例如将 longitude 与 latitude 组合，产生的组合特征则代表一个明确的城市街区。这样能产生比单独考虑单个特征更强烈的位置信息的信号，所以特征组合就是在衍生我们不能直接接触的特征，然后对模型训练有积极影响。(5) 在模型训练过程中都用了什么算法？ LR,RF,GBDT…，然后一一解释每个算法的特色、原理、中间再加点比较（因为都是分类算法）(6) 混淆矩阵，ROC、AUC、召回率、KS、Gini、IV混淆矩阵：</p><p>这个是后面计算 ROC,AUC, 召回率，准确率的基础，所以还是要把这个表格记住：TP：正确肯定——实际是正例，识别为正例FN：错误否定（漏报）——实际是正例，却识别成了负例FP：错误肯定（误报）——实际是负例，却识别成了正例TN：正确否定——实际是负例，识别为负例AccuracyRate(准确率): (TP+TN)/(TP+TN+FN+FP)ErrorRate(误分率): (FN+FP)/(TP+TN+FN+FP)Recall(召回率，查全率, 击中概率): TP/(TP+FN), 在所有 GroundTruth 为正样本中有多少被识别为正样本了;Precision(查准率):TP/(TP+FP), 在所有识别成正样本中有多少是真正的正样本；TPR(TruePositive Rate): TP/(TP+FN), 实际就是 RecallFAR(FalseAcceptance Rate) 或 FPR(False Positive Rate)：FP/(FP+TN)， 错误接收率，误报率，在所有负样本中有多少被识别为正样本了;FRR(FalseRejection Rate): FN/(TP+FN)，错误拒绝率，拒真率，在所有 GroundTruth 为正样本中有多少被识别为负样本了，它等于 1-RecallROC 曲线就是以假阳性概率（False positive rate）为横轴，真阳性（True positive rate）为纵轴所组成的坐标图上面大家可能学习过程中都能接触到，但是 KS、Gini、IV 是互金行业风控模型中常用的指标，一被问到我就懵逼了，完全不知道是啥啊，只能支支吾吾说没用过这些指标。这几个指标内容也比较多，在这附一个讲的比较好的博客地址：<a target="_blank" rel="noopener" href="https://blog.csdn.net/htbeker/article/details/79697557">https://blog.csdn.net/htbeker/article/details/79697557</a> 结果：可能大公司要求就是严格，亦或是一个问题就能看出来你在这个行业待了多长时间，所以：一面，卒。</p><ol><li>对大数据了解多少？hadoop 的原理？<ul><li>重点内容：求职者对大数据处理和Hadoop原理的了解。</li><li>描述：面试官希望求职者介绍对大数据处理工具如Hadoop的了解程度，以及Hadoop的原理和分布式计算。</li></ul></li><li>特征怎么进行组合的，对模型训练有什么指导意义？<ul><li>重点内容：特征组合的意义和方法。</li><li>描述：求职者需要解释特征组合的目的，以及选择特定特征组合的方法，并说明这些组合对模型训练的积极影响。</li></ul></li><li>在模型训练过程中都用了什么算法？LR, RF, GBDT…，然后一一解释每个算法的特色、原理、中间再加点比较（因为都是分类算法）<ul><li>重点内容：模型训练使用的算法及其特点、原理和比较。</li><li>描述：求职者需要列举所用的算法，如逻辑回归（LR）、随机森林（RF）、梯度提升树（GBDT）等，并逐一解释每个算法的特点、原理，并进行比较。</li></ul></li><li>混淆矩阵，ROC、AUC、召回率、KS、Gini、IV<ul><li>重点内容：混淆矩阵和其他评估指标的解释和计算。</li><li>描述：求职者需要对混淆矩阵及其相关指标如ROC、AUC、召回率、KS、Gini、IV进行解释，并了解其在互金行业风控模型中的常用性质。</li></ul></li></ol><p><strong>6．公司：某金融集团，岗位：算法工程师，行业方向：互联网金融</strong></p><p>一面技术：(1) 简单介绍一下自己 千篇一律，当练口才了。(2) 手写快速排序算法，讲原理，最好、最坏时间复杂度，空间复杂度 这个上面也提到了，主要看对算法的理解程度，所以面试中可以不去看那些数据结构，但是常用的算法一定要能默写出来，而且知道为什么快。(3) 简历中写的申请评分卡是怎么做的？ 基于 Logistic 回归的申请评分卡模型开发（主要讲了流程）： ①数据准备：收集并整合在库客户的数据，定义目标变量，排除特定样本。②探索性数据分析：评估每个变量的值分布情况，处理异常值和缺失值。③数据预处理：变量筛选，变量分箱，WOE 转换、样本抽样。④模型开发：逻辑回归拟合模型。⑤模型评估：常见几种评估方法，ROC、KS 等。⑥生成评分卡(4) 做一个风控模型一般流程是什么样的？其实这个问题就是把上面的问题又说了一遍，但是我回来在网上查了一下大概是这个样子的：业务定义 (确定业务才能确定其他的)-&gt; 风险定义 (其实就是定义好用户和坏用户，或者说是正负样本)-&gt; 风险化解 (这块就是用算法训练各种评分卡)-&gt; 风险策略(针对作弊行为或坏账进行的后期行为)(5) 手推 LR，并对每一步进行解释：引入 sigmoid，逻辑回归的公式，极大似然，求解参数时的梯度下降算法 这个没什么可讲的，就是去手推吧，推几遍这些都记住了，包括哪一步该干什么。(6)LR 和 SVM 有什么异同点，怎么理解 SVM 的核函数 异同点和核函数都在上面说过了，这块回顾一下吧 (其实整个这个面经看下来可以看出来，面试官们常问的问题也就这些，只是会从它们的业务中带出问题来)。(7) 项目中样本量是多少？正负样本比例如何？怎么解决正负样本不均衡的问题？ 样本量自己说了几十万，正负样本 10:1(肯定有人问，为什么说 10:1，因为在互金行业的正负样本比是十分不平衡的，每有一个负样本就说明至少出现一笔坏账，在几百万数据的情况下，有 1W 坏账这个公司就别活了，当然我说这个比例也不是很准确的，但是我解释取样本的时候做了采样)。样本不均衡解决方法：负例采样，smote 算法。然后讲了 smote 算法怎么做。(8) 特征工程做了哪些工作? 为什么？ 这个当时就把自己实际用的特征工程方法说了：对 null 值、异常值、文本型、时间型、类别型，组合，统计缺失率等通通说了一遍，然后进行特征选择。这么做当然是为了模型能快速训练出效果，使数据收敛，提升评估指标等等啊，这么做肯定说产生好的影响。(9) 项目中使用模型训练的评估指标是什么？AUC 多少？KS 值多少，KS 值是怎么计算的 吃了百度金融的亏，这回我可答上来了，上面那个连接里面的每个概念、计算方法我都扣了好几遍。AUC：0.73(不能太高也不能太低，有零有整，很真实)，KS：0.28（一般 &gt; 0.2 便说明模型有很好的区分能力） 这个问题其实也是一个不小的坑，因为你说的太假一下子就能看出来，面试官都是在实际工作中摸爬滚打出来的，你说 AUC0.9 那他得仰视你。</p><p>二面技术 + 业务：(1) 在工作中都会用哪些特征来进行模型的训练，哪些数据比较有效 这个主要是跟用户个人和信用方面息息相关的：例如个人基本信息 (年龄、地址、学历、工作…)、设备属性 (手机品牌啊，运营商…)、业务行为 (借贷行为，还款，消费，旅游….)，有效的肯定是跟业务关联多的。因为从这些特征中可以直观的判断这个人的借款需求和还款能力。(2) 对风控模型的理解，完成一个风控系统都需要做哪些工作 ①尽可能全面搜集客户信息 ②根据业务进行模型训练，然后对用户进行评分，完成授信 ③后期监控，防止产生坏账和作弊行为(3) 给一个场景: 有 50W 贷中数据和 50W 贷后数据，特征维度有 300 维，其中还包含了空值，怎么用这些数据做一个申请评分卡？ 讲思想：用贷后数据进行数据分析，做数据处理（空值、异常值）、特征工程，然后计算特征的 IV 值和特征选择方法筛选特征，再把处理完的特征放到 LR 中进行训练 (训练集，验证集按照 7:3 划分)，对模型调优，达到一定指标。贷中数据也别闲着，放到模型里进行预测，放到库中，待时间线临近来验证模型实际应用中的效果。吧啦吧啦，说的口干舌燥，(4) 之前做的项目风险是怎么定义的？ 这个不同公司有不同的定义，银行可能定义 M1 期以后是坏用户，而 P2P 比较脆弱，承担风险能力弱，所以 M0 期可能就定义为坏用户。(5) 有哪些手段防止用户的反欺诈行为？ 这个问题回答的时候尽量从业务的场景去分析，第一，尽可能全面的收集用户的资料，用户资料越全后期用户的行为越可控；第二，授信前要有严格的授信策略 (例如申请评分、贷中行为评分、贷后行为评分)；第三，后对贷后用户进行监控和跟踪，采取电话回访或者其他方式确定用户真实存在。第四，就是不断完善自己的风控系统。(6) 给我找了一批数据，然后发给我，让我回去用这些数据训练一个预测好坏用户的模型。 这个就是实际动手操作了，并不难，回来对数据进行简单的处理，做点特征工程，然后用 LR 和 RF 分别训练了一个模型，然后做一下比较，用 AUC 和 ACC 评估指标说一下效果等等。</p><p>三面人事： 人事这关就是问你为什么辞职啊，上家公司待遇啊，对自己的定位啊，对整个行业的了解啊什么的，跟人事聊天就是让她感觉你很积极向上，离职原因不要贬低自己原来的公司，可以说自己想拓展一些技能啊，进行更多的挑战啊什么的。人事问还有什么问题的时候也尽量问一些关于公司的文化啊，人才培养啊，进阶过程什么的，不要上来就问工资，这个问题等人事主动问你比较好。 结果：拿到 offer，顺利入职总结：BB 这么多，都是我一家公司一家公司面过来的，还有几家公司跟我想从事的方向不一致，问题也都跟这些差不多就没多赘述，问题都是真实记录的，所以有要找互联网金融方面工作的朋友可以参考参考，有些问题我说的不对的也希望指正 (改不改看我心情)，我也学习学习。</p><p>一面技术：</p><ol><li>手写快速排序算法，讲原理，最好、最坏时间复杂度，空间复杂度<ul><li>重点内容：快速排序算法的原理和性能。</li><li>描述：求职者需要手写快速排序算法，并解释其原理，以及对快速排序的最好、最坏时间复杂度和空间复杂度进行说明。</li></ul></li><li>做一个风控模型一般流程是什么样的<ul><li>重点内容：风控模型开发的一般流程。</li><li>描述：求职者需要介绍风控模型开发的一般流程，从业务定义、风险定义、风险化解到风险策略等步骤。</li></ul></li><li>手推 LR，并对每一步进行解释：引入 sigmoid，逻辑回归的公式，极大似然，求解参数时的梯度下降算法<ul><li>重点内容：逻辑回归算法及其步骤的理解。</li><li>描述：求职者需要手推逻辑回归算法，并解释每一步的过程，包括引入sigmoid函数、逻辑回归公式、极大似然估计和参数求解的梯度下降算法。</li></ul></li><li>LR 和 SVM 有什么异同点，怎么理解 SVM 的核函数<ul><li>重点内容：逻辑回归和支持向量机的异同点以及核函数的理解。</li><li>描述：求职者需要比较逻辑回归和支持向量机的异同点，并解释SVM的核函数是如何处理非线性可分问题的。</li></ul></li><li>项目中样本量是多少？正负样本比例如何？怎么解决正负样本不均衡的问题？<ul><li>重点内容：项目中样本量和正负样本比例，以及解决样本不均衡问题的方法。</li><li>描述：求职者需要说明项目中的样本量和正负样本比例，以及通过负例采样或SMOTE算法等方法解决样本不均衡问题。</li></ul></li><li>特征工程做了哪些工作? 为什么？<ul><li>重点内容：特征工程的方法和目的。</li><li>描述：求职者需要介绍自己在项目中做的特征工程，包括对特征的处理和选择方法，并说明这些工作对模型的影响。</li></ul></li><li>项目中使用模型训练的评估指标是什么？AUC 多少？KS 值多少，KS 值是怎么计算的<ul><li>重点内容：模型训练评估指标和KS值的计算方法。</li><li>描述：求职者需要列举在项目中使用的模型训练评估指标，如AUC和KS值，并解释KS值的计算方法。</li></ul></li></ol><p>二面技术 + 业务：</p><ol><li>在工作中都会用哪些特征来进行模型的训练，哪些数据比较有效<ul><li>重点内容：特征选择和数据有效性。</li><li>描述：求职者需要列举在工作中常用的特征，并解释哪些特征对模型的训练更有效。</li></ul></li><li>对风控模型的理解，完成一个风控系统都需要做哪些工作<ul><li>重点内容：风控模型和风控系统的理解。</li><li>描述：求职者需要解释对风控模型的理解，以及完成一个风控系统所需的各项工作。</li></ul></li><li>给一个场景: 有 50W 贷中数据和 50W 贷后数据，特征维度有 300 维，其中还包含了空值，怎么用这些数据做一个申请评分卡？<ul><li>重点内容：利用贷中和贷后数据构建评分卡模型。</li><li>描述：求职者需要讲述利用贷中和贷后数据进行数据处理和特征工程，然后使用逻辑回归构建评分卡模型。</li></ul></li><li>之前做的项目风险是怎么定义的？<ul><li>重点内容：项目中风险的定义。</li><li>描述：求职者需要解释之前项目中对风险的定义方式，可能涉及到逾期定义、坏账定义等。</li></ul></li><li>有哪些手段防止用户的反欺诈行为？<ul><li>重点内容：防止用户反欺诈行为的方法。</li><li>描述：求职者需要介绍防止用户反欺诈行为的手段，包括收集全面用户资料、授信策略、贷后监控等。</li></ul></li></ol><p>参考链接：</p><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/715771">https://developer.aliyun.com/article/715771</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/164607326">RF, GBDT,XGBOOST, LGBM - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/100763009">【机器学习面试总结】—— LR（逻辑回归） - 知乎 (zhihu.com)</a></p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95%E4%B8%8E%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF/" class="category-chain-item">职业发展与个人成长</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/DeepLearning/" class="print-no-link">#DeepLearning</a> <a href="/tags/%E9%87%91%E8%9E%8D/" class="print-no-link">#金融</a></div></div><div class="license-box my-3"><div class="license-title"><div>金融领域机器学习实习生面试经验与题目</div><div>https://fulequn.github.io/2023/08/Article202308041/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Fulequn</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年8月4日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/08/Article202308071/" title="固定收益投资个人入门指南"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">固定收益投资个人入门指南</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/08/Article202308031/" title="在Python中解决自定义类型比较的问题"><span class="hidden-mobile">在Python中解决自定义类型比较的问题</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>